
```{r, include=FALSE, eval=FALSE}
tempR <- tempfile(fileext = ".R")
library(knitr)
purl("../index.Rmd", output = tempR)
source(tempR)
unlink(tempR)
```

```{r, include = FALSE}
library(DesignLibrary)
library(DeclareDesign)
```

## Simple Random Sampling

Often we are interested in features of a population, but data on the entire population is prohibitively expensive to collect. Instead, researchers obtain data on a small fraction of the population and use measurements taken on that sample to draw inferences about the population.

Imagine we seek to estimate the average political ideology of residents of the small town of Portola, California, on a left-right scale that varies from 1 (most liberal) to 7 (most conservative). We draw a simple random sample in which all residents have an equal chance of inclusion in the study. It's a straightforward design but formally declaring it will make it easy to assess its properties. 

### Design Declaration

- **M**odel: 

    Even for this most basic of designs, researchers bring to bear a background model of the world. As described in Chapter 1, the three elements of a model are the signature, probability distributions over variables, and functional equations among variables. The signature here is a specification of the variable of interest, $Y$, with a well defined domain (seven possible values between 1 and 7). In the code declaration below, we assume a uniform distribution over these 7 values. This choice is a speculation about the population distribution of $Y$; some features of the design diagnosis will depend on the choice of distribution. The functional equations seem absent here as there is only one variable in the model. We could consider an elaboration of the model that includes three variables: the true outcome, $Y$; the decision to measure the outcome, $M$; and the measured outcome, $Y^M$. We ignore this complication for now under the assumption that $Y = Y^M$, i.e., that $Y$ is measured perfectly. Finally, the model also includes information about the size of the population. Portola, California, has a population of approximately 2100 people as of 2010, so $N = 2100$.

- **I**nquiry: 

    Our inquiry is the population mean of $Y$: $\frac{1}{N} \sum_1^N Y_i = \bar{Y}$.
    
- **D**ata strategy: 

    In simple random sampling, we draw a random sample without replacement of size $n$, where every member of the population has an equal probability of inclusion in the sample, $\frac{n}{N}$. When $N$ is very large relative to $n$, units are drawn approximately independently. In this design we measure $Y$ for $n=100$ units in the sample; the other $N-n$ units are not measured.

- **A**nswer strategy: 

    We estimate the population mean with the sample mean estimator: $\widehat{\overline{Y}} = \frac{1}{n} \sum_1^n Y_i$. Even though our inquiry implies our answer should be a single number, an answer strategy typically also provides statistics that help us assess the uncertainty around that single number. To construct a 95\% confidence interval around our estimate, we calculate the standard error of the sample mean, then approximate the sampling distribution of the sample mean estimator using a formula that includes a finite population correction. In particular, we approximate the estimated sampling distribution by a $t$ distribution with $n - 1$ degrees of freedom. In the code for our answer strategy, we spell out each step in turn. 

```{r}
# Model -------------------------------------------------------------------
N <- 2100
fixed_population <- declare_population(N = N, Y = sample(1:7, N, replace = TRUE))()
population <- declare_population(data = fixed_population)

# Inquiry -----------------------------------------------------------------
estimand <- declare_estimand(Ybar = mean(Y))

# Data Strategy -----------------------------------------------------------
n <- 100
sampling <- declare_sampling(n = n)

# Answer Strategy ---------------------------------------------------------
estimator <- declare_estimator(Y ~ 1,
                               model = lm_robust,
                                       estimand = estimand,
                                       label = "Sample Mean Estimator")

# Design ------------------------------------------------------------------
design <- population + estimand +  sampling + estimator

diagnosands <- declare_diagnosands(select = c(bias, coverage, mean_estimate, sd_estimate))
```

### Takeaways

With the design declared we can run a diagnosis and plot results from Monte Carlo simulations of the design:

```{r, eval = FALSE}
diagnosis <- diagnose_design(
  design, sims = 10000, bootstrap_sims = 1000, diagnosands = diagnosands) 
```


<!-- ```{r, echo=FALSE, eval = rerun_templates} -->
<!-- diagnosis <- diagnose_design(design, sims = sims, bootstrap = TRUE,bootstrap_sims = 1000, diagnosands = diagnosands) -->
<!-- diagnosis$diagnosands$mean_estimand <- mean(diagnosis$simulations$estimand) -->
<!-- saveRDS(diagnosis, file = "../examples_data/srs_diagnosis.rds") -->
<!-- saveRDS(design, file = "../examples_data/srs_design.rds") -->
<!-- ``` -->

<!-- ```{r, echo = FALSE} -->
<!-- diagnosis <- readRDS("../examples_data/srs_diagnosis.rds") -->
<!-- diagnosis_table <- get_diagnosands(diagnosis)[,c("mean_est","bias","se(bias)","coverage","se(coverage)")] -->
<!-- colnames(diagnosis_table) <- c("Mean Estimate","Bias","SE(Bias)","Coverage","SE(Coverage)") -->
<!-- kable(diagnosis_table, digit = 3) -->
<!-- ``` -->

<!-- ```{r, echo=FALSE, fig.height = 3.5} -->
<!-- local_sims <- get_simulations(diagnosis) %>%  -->
<!--   mutate(sim_order = fct_reorder(factor(sim_ID), x = (ci_lower + ci_upper)/2), -->
<!--          covers = as.numeric(ci_lower <= estimand & ci_upper >= estimand), -->
<!--          mean_estimand = mean(estimand)) -->
<!-- local_diagnosis <- get_diagnosands(diagnosis) -->
<!-- local_diagnosis$mean_estimand <- mean(local_sims$mean_estimand) -->

<!--       g1 <-  -->
<!--         local_sims %>% -->
<!--         ggplot(aes(est)) + -->
<!--         geom_histogram(bins = 50) + -->
<!--         geom_vline(data = local_diagnosis, aes(xintercept = mean_estimand),  -->
<!--                    color = "red", linetype = "dashed") + -->
<!--         dd_theme() + -->
<!--         theme(axis.text.y = element_blank(), -->
<!--               axis.title.y = element_blank(), -->
<!--               axis.ticks.y = element_blank(), -->
<!--               legend.position = "none",  -->
<!--               panel.grid.major = element_blank()) + -->
<!--         # coord_cartesian(xlim = c(3.5, 0.75)) + -->
<!--         xlab("Sample Mean Estimates")  -->

<!--       g2 <- -->
<!--         local_sims %>% -->
<!--         ggplot(aes(y = sim_order, x = est, color = covers)) + -->
<!--         geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0) + -->
<!--         geom_vline(data = local_diagnosis, aes(xintercept = mean_estimand),  -->
<!--                    color = "red", linetype = "dashed") + -->
<!--         dd_theme() + -->
<!--         theme(axis.text.y = element_blank(), -->
<!--               axis.title.y = element_blank(), -->
<!--               axis.ticks.y = element_blank(), -->
<!--               legend.position = "none",  -->
<!--               panel.grid.major = element_blank()) + -->
<!--         # coord_cartesian(xlim = c(0.25, 0.75)) + -->
<!--         xlab("95% Confidence Intervals") -->

<!-- #if (knitr::opts_knit$get("rmarkdown.pandoc.to") != "html") { -->
<!--   #grid.arrange(g1, g2, ncol = 2) -->
<!-- #} -->
<!-- ``` -->

The diagnosis indicates that under simple random sampling, the sample mean estimator of the population mean is unbiased. The graph on the left shows the sampling distribution of the estimator: it's centered directly on the true value of the inquiry. Confidence intervals **also** have a sampling distribution -- they change depending on the idiosyncrasies of each sample we happen to draw. The figure on the right shows that the 95% of the time the confidence intervals cover the true value of the estimand, as they should. As sample size grows, the sampling distribution of the estimator gets tighter, but the coverage of the confidence intervals stays at 95% -- just the properties we would want out of our answer strategy.

Things work well here it seems. In the exercises we suggest some small modifications of the design that point to conditions under which things might break down.

### Exercises

1. Modify the declaration to change the distribution of $Y$ from being uniform to something else: perhaps imagine that more extreme ideologies are more prevalent than moderate ones. Is the sample mean estimator still unbiased? Interpret your answer.
2. Change the sampling procedure to favor units with higher values of ideology. Is the sample mean estimator still unbiased? Interpret your answer.
3. Modify the estimation function to use this formula for the standard error: $\widehat{se} \equiv \frac{\widehat\sigma}{\sqrt{n}}$. This equation differs from the one used in our declaration (it ignores the total population size $N$). Check that the coverage of this new design is incorrect when $N=n$. Assess how large $N$ has to be for the difference between these procedures not to matter. 

### Design Inspector

<iframe src="https://graemeblair.shinyapps.io/inspect_design/?design=srs" style="border: none; width: 100%; height: 550px"></iframe>
