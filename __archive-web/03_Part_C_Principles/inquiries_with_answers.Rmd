```{r, echo = FALSE, eval = TRUE, results='hide', message = FALSE, warning = FALSE}
tempR <- tempfile(fileext = ".R")
library(knitr)
purl("../index.Rmd", output = tempR)
source(tempR)
unlink(tempR)
```

## Inquiries should have answers

A fundamental requirement of a good research design is that the question it seeks to answer does in fact *have* an answer, at least under plausible models of the world. In our framework, this means that an inquiry $I$ must have an associated answer $a^M$, which refers to the answer under the model. 

How could a question not have an answer? This happens when inquiries depend on variables that do not exist or are undefined for some units. In other words, there is a mismatch between the model and the inquiry: we're asking a question that doesn't have an answer. 

We'll illustrate this general point with specifics from three very different kinds of studies: a fundraising experiment, an audit study, and a health trial. The fundraising experiment is designed to measure the average treatment effect of a donation matching guarantee from a foundation on *whether* and *how much* individual donors give. The audit study seeks to measure the average effect of an email from a Latino name (versus a White name) on *whether* and *how well* election officials respond to requests for infomation. The health trial estimates the impact of a community-based monitoring program on *whether* infants survive birth and *how much* they weigh.

Each of these three studies have two inquiries. They first ask about the average effect of treatment on *whether* something happens. They then ask, *conditional* on something happening -- what the average effect of treatment is on a subsequent outcome. It's this second question that doesn't have an answer.

- **M**odel: 

The model has two outcome variables, $R_i$ and $Y_i$. $R_i$ stands for "response" and refers to the "whether" questions: It's equal to 1 if a donation is made, a request for information is responded to, or an infant is born. $Y_i$ is the second outcome -- the amount of the donation, the quality of the reponse, the weight of the child. 

The model also considers the potential outcomes of $R_i$ and $Y_i$ depending on whether or not subject $i$ is treated. The treatments are the matching guarantee, the email from the latino name, or the community-based monitoring program.

The table below shows the four possible types of subjects, depending on the potential outcomes of $R_i$. A types respond regardless of treatment; D types fail to respond, regardless of treatment. B and C types change whether they respond, depending on their treatment status. B types respond if and only if they are treated and C types respond if and only if they are *not* treated.

The table also includes columns for the potential outcomes of $Y_i$. For A types, our model of potential outcomes proceeds as normal. We don't know what the values of $Y_i(0)$ and $Y_i(1)$ are for the A types, but at least we know they exist. Regardless of treatment, A types donate -- hopefully the treatment makes them donate more. Regardless of treatment, A types respond to requests for information -- hopefully the quality of the information they provide *isn't* different. Regardless of treatment, A types survive childbirth and we hope that the treatment increases their health as measured by their weight.

For the B, C, and D types, the effect of treatment on $Y_i$ is *undefined*! Donations never made have no amount; Emails never sent have no content; Children never born have no weight. 

The last (and very important) feature of our model is that the outcomes $Y_i$ are possibly correlated with subject type. Even though both $E[Y_i(1) | Type = A]$ and $E[Y_i(1) | Type = B]$ exist, there's no reason to expect that they are equal. When we draw the potential outcomes $Y_i(1)$ and $Y_i(0)$ (from a normal distribution for convenience), we'll build in some correlation with type.

| Type | $R_i(0)$ | $R_i(1)$ | $Y_i(0)$ | $Y_i(1)$ |
| ---- | -------- | -------- | -------- | -------- |
| A    | 1        | 1        | $Y_i(0)$ | $Y_i(1)$ |
| B    | 0        | 1        | NA       | $Y_i(1)$ |
| C    | 1        | 0        | $Y_i(0)$ | NA       |
| D    | 0        | 0        | NA       | NA       |

Table: Causal Types 

- **I**quiry These experiments have two inquiries. The first inquiry is straightforward (and is identical to the inquiry discussed in the Two Arm Experiment): $E[R_i(1) - R_i(0)]$ is the Average Treatment Effect on response. The second inquiry is tricky. If we set the inquiry to $E[Y_i(1) - Y_i(0)]$, we have an inquired that is undefined, because we can't compute $Y_i(1) - Y_i(0)$ for the B, C, or D types. 

The solution to this problem is to change the inquiry. The average effect of treatment on $Y_i$ among the A type is well-defined. We can therefore set our inquiry to $E[Y_i(1) - Y_i(0) | Type = A]$. 

- **D**ata strategy: The data strategy will be to use complete random assignment to assign 250 of 500 units to treatment.

- **A**nswer strategy: We'll try and answer both inquiries with the difference-in-means estimator. 

```{r}
# Model -------------------------------------------------------------------
population <-
  declare_population(
    N = 500,
    type = sample(c("A", "B", "C", "D"), size = N, replace = TRUE, prob = c(.40, .05, .10, .45))
  )

potential_outcomes <-
  declare_potential_outcomes(
    R_Z_0 = type %in% c("A", "C"),
    R_Z_1 = type %in% c("A", "B"),
    Y_Z_0 = ifelse(R_Z_0, rnorm(n = sum(R_Z_0), mean = .1*(type == "A") - 2*(type == "C")), NA),
    Y_Z_1 = ifelse(R_Z_1, rnorm(n = sum(R_Z_1), mean = .2*(type == "A") + 2*(type == "B")), NA)
  )

# Inquiry -----------------------------------------------------------------
estimand_1 <- declare_estimand(mean(R_Z_1 - R_Z_0), label = "ATE on Response")
estimand_2 <- declare_estimand(mean(Y_Z_1[type == "A"] - Y_Z_0[type == "A"]), label = "ATE on Amount Among As")

# Data Strategy -----------------------------------------------------------
assignment <- declare_assignment()

# Answer Strategy ---------------------------------------------------------
estimator_1 <- declare_estimator(R ~ Z, model = difference_in_means, estimand = estimand_1, label = "ATE on Response")
estimator_2 <- declare_estimator(Y ~ Z, model = difference_in_means, estimand = estimand_2, label = "ATE on Amount")

# Design ------------------------------------------------------------------
design <- declare_design(
  population,
  potential_outcomes,
  assignment,
  estimand_1, estimand_2,
  reveal_outcomes(outcome_variable_names = c("R", "Y")),
  estimator_1, estimator_2
)
```

```{r,eval = FALSE}
diagnosis <- diagnose_design(design, sims = 1000, bootstrap = FALSE)
```

```{r, echo=FALSE, eval = rerun_templates}
diagnosis <- diagnose_design(design, sims = 1000, bootstrap = FALSE)
saveRDS(diagnosis, file = "../examples_data/inquires_with_answers.RDS")
```

```{r, echo=FALSE, eval = !rerun_templates}
diagnosis <- readRDS("../examples_data/inquires_with_answers.RDS")
```

### Takeaways

```{r, echo=FALSE, caption = "Sampling Distribution of Two Estimators", fig.height = 3}
diagnosis$simulations %>%
  ggplot(aes(est)) + geom_histogram(bins = 30) +
  facet_wrap(~estimand_label, scales = "free") +
  geom_vline(data = diagnosis$diagnosands, aes(xintercept = mean_estimand), color = "red") +
  theme(axis.title = element_blank()) +
  dd_theme +
  theme(axis.title = element_blank())
```

The principle that inquiries should have answers seems, on its face, so obvious as to not need stating. But many research settings involve imagining unobservable quantites. In some cases, our model says that those quantities exist but are unobserved, such as in descriptive studies that aim to measure a latent trait or in causal studies that aim to estimate counterfactuals. In other cases, however, our model implies that some quantites are not just unobserved, *they don't even exist*.

This problem goes beyond picking the right estimator so as to avoid "post-treatment bias." The main problem in these examples is conceptual: the effect of treatment on the outcome just doesn't exist for some subjects.

How should we solve this problem? There are three main approaches:

1. Abandon the second inquiry. Because the observed data won't reveal who the A types are, the question is fundamentally unidentified and can't be answered.

2. Use bounds. Aronow, Baron, and Pinson (2017) develop an estimator that places bounds around the ATE among A types using information that the observered data does reveal.

3. Redefine the inquiry once more. We can consider a new variable $Y^*_i$ that is equal to 0 when $Y_i$ is undefined. This would imply that the amount donation never made is 0, the quality of an email never sent is 0, and the weight of a child never born is 0 as well. This approach probably makes more sense for the fundraising experiment than for the health trial.


### Exercises

1. The 

2. Imagine that discrimination has no effect on whether a subject responds to an email, but it does affect the friendliness of an email. Which, if any, of the estimators are biased?

3. Experiments on donations often seek to measure the effect of an intervention on whether a donation is made at all and on the size of a donation. Declare and diagnose a research design for such an experiment, being careful not to induce post-treatment bias.
